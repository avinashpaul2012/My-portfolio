<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Project 3: Automatic Detection and Classication of Colonic Polyp using deep learning | Avinash Paul</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="Monsieur the Cardinal">
    <meta name="generator" content="Hugo 0.83.1" />
    
    
      <META NAME="ROBOTS" CONTENT="NOINDEX, NOFOLLOW">
    

    

  
  
    <link rel="stylesheet" href="https://avinashpaul2012.github.io/My-portfolio/ananke/dist/main.css_5c99d70a7725bacd4c701e995b969fea.css" >
  




    
      

    

    
    
    <meta property="og:title" content="Project 3: Automatic Detection and Classication of Colonic Polyp using deep learning" />
<meta property="og:description" content="Monsieur the Cardinal" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://avinashpaul2012.github.io/My-portfolio/post/project-3/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2021-07-11T11:13:32-04:00" />
<meta property="article:modified_time" content="2021-07-11T11:13:32-04:00" /><meta property="og:site_name" content="Avinash Paul" />

<meta itemprop="name" content="Project 3: Automatic Detection and Classication of Colonic Polyp using deep learning">
<meta itemprop="description" content="Monsieur the Cardinal"><meta itemprop="datePublished" content="2021-07-11T11:13:32-04:00" />
<meta itemprop="dateModified" content="2021-07-11T11:13:32-04:00" />
<meta itemprop="wordCount" content="848">
<meta itemprop="keywords" content="Detection,Classification," /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Project 3: Automatic Detection and Classication of Colonic Polyp using deep learning"/>
<meta name="twitter:description" content="Monsieur the Cardinal"/>

	
  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  
  
  <header class="cover bg-top" style="background-image: url('https://avinashpaul2012.github.io/My-portfolio/images/Detection_and_localization_results_on_test_data.JPG');">
    <div class="pb3-m pb6-l bg-black-60">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="https://avinashpaul2012.github.io/My-portfolio/" class="f3 fw2 hover-white no-underline white-90 dib">
      
        Avinash Paul
      
    </a>
    <div class="flex-l items-center">
      

      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="https://avinashpaul2012.github.io/My-portfolio/about/" title="About page">
              About
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="https://avinashpaul2012.github.io/My-portfolio/contact/" title="Contact page">
              Contact
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="https://avinashpaul2012.github.io/My-portfolio/post/" title="Projects page">
              Projects
            </a>
          </li>
          
        </ul>
      
      







<a href="https://www.linkedin.com/in/avinash-paul-551291aa" target="_blank" class="link-transition linkedin link dib z-999 pt3 pt0-l mr1" title="LinkedIn link" rel="noopener" aria-label="follow on LinkedIn——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>


<a href="https://github.com/avinashpaul2012" target="_blank" class="link-transition github link dib z-999 pt3 pt0-l mr1" title="Github link" rel="noopener" aria-label="follow on Github——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 512 512;" version="1.1" viewBox="0 0 512 512" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
  <path d="M256,32C132.3,32,32,134.8,32,261.7c0,101.5,64.2,187.5,153.2,217.9c11.2,2.1,15.3-5,15.3-11.1   c0-5.5-0.2-19.9-0.3-39.1c-62.3,13.9-75.5-30.8-75.5-30.8c-10.2-26.5-24.9-33.6-24.9-33.6c-20.3-14.3,1.5-14,1.5-14   c22.5,1.6,34.3,23.7,34.3,23.7c20,35.1,52.4,25,65.2,19.1c2-14.8,7.8-25,14.2-30.7c-49.7-5.8-102-25.5-102-113.5   c0-25.1,8.7-45.6,23-61.6c-2.3-5.8-10-29.2,2.2-60.8c0,0,18.8-6.2,61.6,23.5c17.9-5.1,37-7.6,56.1-7.7c19,0.1,38.2,2.6,56.1,7.7   c42.8-29.7,61.5-23.5,61.5-23.5c12.2,31.6,4.5,55,2.2,60.8c14.3,16.1,23,36.6,23,61.6c0,88.2-52.4,107.6-102.3,113.3   c8,7.1,15.2,21.1,15.2,42.5c0,30.7-0.3,55.5-0.3,63c0,6.1,4,13.3,15.4,11C415.9,449.1,480,363.1,480,261.7   C480,134.8,379.7,32,256,32z"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>








    </div>
  </div>
</nav>

      <div class="tc-l pv6 ph3 ph4-ns">
        
          <h1 class="f2 f1-l fw2 white-90 mb0 lh-title">Project 3: Automatic Detection and Classication of Colonic Polyp using deep learning</h1>
          
            <h2 class="fw1 f5 f3-l white-80 measure-wide-l center lh-copy mt3 mb4">
              Monsieur the Cardinal
            </h2>
          
        
      </div>
    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked">
          
        PROJECTS
      </aside>
      




  <div id="sharing" class="mt3">

    
    <a href="https://www.facebook.com/sharer.php?u=https://avinashpaul2012.github.io/My-portfolio/post/project-3/" class="facebook no-underline" aria-label="share on Facebook">
      <svg height="32px"  style="enable-background:new 0 0 67 67;" version="1.1" viewBox="0 0 67 67" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M28.765,50.32h6.744V33.998h4.499l0.596-5.624h-5.095  l0.007-2.816c0-1.466,0.14-2.253,2.244-2.253h2.812V17.68h-4.5c-5.405,0-7.307,2.729-7.307,7.317v3.377h-3.369v5.625h3.369V50.32z   M33,64C16.432,64,3,50.569,3,34S16.432,4,33,4s30,13.431,30,30S49.568,64,33,64z" style="fill-rule:evenodd;clip-rule:evenodd;"/></svg>

    </a>

    
    
    <a href="https://twitter.com/share?url=https://avinashpaul2012.github.io/My-portfolio/post/project-3/&amp;text=Project%203:%20Automatic%20Detection%20and%20Classication%20of%20Colonic%20Polyp%20using%20deep%20learning" class="twitter no-underline" aria-label="share on Twitter">
      <svg height="32px"  style="enable-background:new 0 0 67 67;" version="1.1" viewBox="0 0 67 67" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M37.167,22.283c-2.619,0.953-4.274,3.411-4.086,6.101  l0.063,1.038l-1.048-0.127c-3.813-0.487-7.145-2.139-9.974-4.915l-1.383-1.377l-0.356,1.017c-0.754,2.267-0.272,4.661,1.299,6.271  c0.838,0.89,0.649,1.017-0.796,0.487c-0.503-0.169-0.943-0.296-0.985-0.233c-0.146,0.149,0.356,2.076,0.754,2.839  c0.545,1.06,1.655,2.097,2.871,2.712l1.027,0.487l-1.215,0.021c-1.173,0-1.215,0.021-1.089,0.467  c0.419,1.377,2.074,2.839,3.918,3.475l1.299,0.444l-1.131,0.678c-1.676,0.976-3.646,1.526-5.616,1.568  C19.775,43.256,19,43.341,19,43.405c0,0.211,2.557,1.397,4.044,1.864c4.463,1.377,9.765,0.783,13.746-1.568  c2.829-1.673,5.657-5,6.978-8.221c0.713-1.716,1.425-4.851,1.425-6.354c0-0.975,0.063-1.102,1.236-2.267  c0.692-0.678,1.341-1.419,1.467-1.631c0.21-0.403,0.188-0.403-0.88-0.043c-1.781,0.636-2.033,0.551-1.152-0.402  c0.649-0.678,1.425-1.907,1.425-2.267c0-0.063-0.314,0.042-0.671,0.233c-0.377,0.212-1.215,0.53-1.844,0.72l-1.131,0.361l-1.027-0.7  c-0.566-0.381-1.361-0.805-1.781-0.932C39.766,21.902,38.131,21.944,37.167,22.283z M33,64C16.432,64,3,50.569,3,34S16.432,4,33,4  s30,13.431,30,30S49.568,64,33,64z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/></svg>

    </a>

    
    <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://avinashpaul2012.github.io/My-portfolio/post/project-3/&amp;title=Project%203:%20Automatic%20Detection%20and%20Classication%20of%20Colonic%20Polyp%20using%20deep%20learning" class="linkedin no-underline" aria-label="share on LinkedIn">
      <svg  height="32px"  style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>

    </a>
  </div>


      <h1 class="f1 athelas mt3 mb1">Project 3: Automatic Detection and Classication of Colonic Polyp using deep learning</h1>
      
      
      <time class="f6 mv4 dib tracked" datetime="2021-07-11T11:13:32-04:00">July 11, 2021</time>

      
      
    </header>
    <div class="nested-copy-line-height lh-copy serif f4 nested-links nested-img mid-gray pr4-l w-two-thirds-l"><p>Colorectal cancer (CRC) in its advanced stage is one of the leading causes of death worldwide. However, early detection of
polyps which are the precursor to such cancer can lead to better prognosis and clinical management. This report proposes an
automated diagnostic technique to detect, localize, and classify polyps in colonoscopy video frames. Manual detection and
localization of polyps on hugely acquired colonic frames have many limitations. Our deep learning-based framework proposes
an attention-based YOLOv4 detector for polyp detection and localization. Finally, leveraging a fusion of deep and handcrafted
features of the polyps, the detected polyps are classified as benign or malignant.</p>
<figure><img src="https://avinashpaul2012.github.io/My-portfolio/images/Proposed_method_detection.JPG"/><figcaption>
            <h4>Proposed algorithm</h4>
        </figcaption>
</figure>

<p>The individual and the cross-database
performances on two databases suggest the robustness of our method in polyp localization. The comparison of our approach
based on significant clinical parameters with current state-of-the-art methods confirms that our method can be used for
automated polyp localization in both real-time and offline colonoscopic video frames. Our method can give an average precision
of 0.8971 and 0.9171 and an average IoU of 0.8325 and 0.8179 for the Kvsir-SEG and SUN databases, respectively. Similarly,
our proposed classification framework on the detected polyps yields a classification accuracy of 96.66% on a public dataset.</p>
<figure><img src="https://avinashpaul2012.github.io/My-portfolio/images/attention_yolo_network.JPG"/><figcaption>
            <h4>Proposed attention YOLOv4 network</h4>
        </figcaption>
</figure>

<p>YOLO is a single-step object detection model and is considered superior to other deep learning models owing to its optimal
accuracy and detection speed. Further, YOLOv2 and YOLOv3 were proposed which show improved detection performances. In YOLOv3, a CNN Darknet53 is employed as a backbone of the architecture, efficiently extracting features from
the input image. Later, YOLOv4 was proposed by Bochkovskiy et al. to enhance the detection performance and speed. It
integrates all the efficient approaches which are employed in different domains. Though it performs well on various datasets, its
applicability and generalizability to medical imaging cannot be guaranteed. The medical images, especially endoscopic video
frames, are generally of low quality, and they may have high noise, specularity, blur, etc. Also, a lack of annotated data may
lead to overfitting the YOLOv4 model and make it less efficient in polyp detection and localization. Therefore, some changes
corresponding to the polyp characteristics of endoscopic video frames are made in the existing model for better performances.</p>
<figure><img src="https://avinashpaul2012.github.io/My-portfolio/images/Channel_attention_block.JPG"/><figcaption>
            <h4>Channel Attention Block</h4>
        </figcaption>
</figure>

<p>Occlusion, clutter, poor image quality, noise, etc., degrade detection performances. Generally, endoscopy videos suffer from
such limitations. Also, the bounding box (BBoxes) used to localize the target objects may fit the arbitrary contour of objects.
Therefore, various methods are generally adopted to highlight the real target object neglecting the background. The attention
mechanism is among the solutions to these problems by enabling the network to focus more on the target object. Attention
mechanisms are coupled in deep detection models to learn key features of the object. It mimics the property of the human
visual system. Recently, attention mechanism has shown promising performances in various computer vision applications.
Therefore, the attention module is embedded into the backbone of CSP Darknet to focus more on the ROI of feature maps.</p>
<figure><img src="https://avinashpaul2012.github.io/My-portfolio/images/Spatial_attention_block.JPG"/><figcaption>
            <h4>Spatial Attention Block</h4>
        </figcaption>
</figure>

<p>This module would enable extraction of the polyp regions’ important features, ignoring the non-polyp regions of colonoscopy
frames. Our method proposes two attention modules, namely, the channel attention module and spatial attention module, and
are incorporated in the backbone of YOLOv4. YOLOv4 extracts feature maps to three different branches to obtain three feature
grid maps with various scales for detecting objects of different sizes. The three YOLO heads are then trying to localize the 
objects with the BBoxes. Our proposed attention modules are integrated on the feature maps before the three YOLO heads can
detect and localize polyps.</p>
<figure><img src="https://avinashpaul2012.github.io/My-portfolio/images/proposed_classification_network.JPG"/><figcaption>
            <h4>Proposed classification network</h4>
        </figcaption>
</figure>

<p>Following the identification of polyps, endoscopists split off the polyp areas and vividly access them for cancer diagnosis. They
do this by analysing several polyp features such as shape, colour, texture, and surface patterns etc. Due to the large medical
images acquired during colonoscopy and the similarity in pathological manifestations across ailments, physical inspection
and labelling of polyps is tedious and inefficient. The polyp characteristics may not always be visible to the human eye, and
diagnostic information may be ignored, making decision-making extremely challenging. An automated polyp classifier for
two-class polyp classification, i.e., adenoma (malignant) and hyperplastic (benign), is provided in this report to solve the
aforementioned problems.</p>
<figure><img src="https://avinashpaul2012.github.io/My-portfolio/images/Detection_and_localization_results_on_test_data.JPG"/><figcaption>
            <h4>Detection results on test data</h4>
        </figcaption>
</figure>

<p>This paper presents a framework for analysis of colonic polyps using colonoscopy video frames. A deep attention based
YOLOv4 network is proposed to detect and localise polyps in the first step of the study. The performance of the suggested
algorithm outperforms state-of-the-art approaches by a significant margin. The generalizability and robustness of our method
are also demonstrated by the consistency of results across datasets and between datasets. Following that, the localised polyps
are classified, which is crucial for better prognosis. We propose a triplet network based on siamese architecture, followed by
SVM, to achieve this. Additionally, local polyp features are extracted and fused with deep features, resulting in improved
classification results. The effectiveness of our strategy in a limited data environment is demonstrated by its classification
performance on a relative small dataset.</p>
<ul class="pa0">
  
   <li class="list">
     <a href="https://avinashpaul2012.github.io/My-portfolio/tags/detection" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">Detection</a>
   </li>
  
   <li class="list">
     <a href="https://avinashpaul2012.github.io/My-portfolio/tags/classification" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">Classification</a>
   </li>
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




  <div class="bg-light-gray pa3 nested-list-reset nested-copy-line-height nested-links">
    <p class="f5 b mb3">Related</p>
    <ul class="pa0 list">
	   
	     <li  class="mb2">
          <a href="https://avinashpaul2012.github.io/My-portfolio/post/project-2/">Project 2: A Data-efficient Classifier using GAN</a>
        </li>
	    
    </ul>
</div>

</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="https://avinashpaul2012.github.io/My-portfolio/" >
    &copy;  Avinash Paul 2021 
  </a>
    <div>







<a href="https://www.linkedin.com/in/avinash-paul-551291aa" target="_blank" class="link-transition linkedin link dib z-999 pt3 pt0-l mr1" title="LinkedIn link" rel="noopener" aria-label="follow on LinkedIn——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>


<a href="https://github.com/avinashpaul2012" target="_blank" class="link-transition github link dib z-999 pt3 pt0-l mr1" title="Github link" rel="noopener" aria-label="follow on Github——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 512 512;" version="1.1" viewBox="0 0 512 512" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
  <path d="M256,32C132.3,32,32,134.8,32,261.7c0,101.5,64.2,187.5,153.2,217.9c11.2,2.1,15.3-5,15.3-11.1   c0-5.5-0.2-19.9-0.3-39.1c-62.3,13.9-75.5-30.8-75.5-30.8c-10.2-26.5-24.9-33.6-24.9-33.6c-20.3-14.3,1.5-14,1.5-14   c22.5,1.6,34.3,23.7,34.3,23.7c20,35.1,52.4,25,65.2,19.1c2-14.8,7.8-25,14.2-30.7c-49.7-5.8-102-25.5-102-113.5   c0-25.1,8.7-45.6,23-61.6c-2.3-5.8-10-29.2,2.2-60.8c0,0,18.8-6.2,61.6,23.5c17.9-5.1,37-7.6,56.1-7.7c19,0.1,38.2,2.6,56.1,7.7   c42.8-29.7,61.5-23.5,61.5-23.5c12.2,31.6,4.5,55,2.2,60.8c14.3,16.1,23,36.6,23,61.6c0,88.2-52.4,107.6-102.3,113.3   c8,7.1,15.2,21.1,15.2,42.5c0,30.7-0.3,55.5-0.3,63c0,6.1,4,13.3,15.4,11C415.9,449.1,480,363.1,480,261.7   C480,134.8,379.7,32,256,32z"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>







</div>
  </div>
</footer>

  </body>
</html>
